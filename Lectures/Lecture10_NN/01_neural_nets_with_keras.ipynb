{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "\n",
       ".rendered_html\n",
       "{\n",
       "  color: #2C5494;\n",
       "  font-family: Ubuntu;\n",
       "  font-size: 140%;\n",
       "  line-height: 1.1;\n",
       "  margin: 0.5em 0;\n",
       "  }\n",
       "\n",
       ".talk_title\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 250%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 10px 50px 10px;\n",
       "  }\n",
       "\n",
       ".subtitle\n",
       "{\n",
       "  color: #386BBC;\n",
       "  font-size: 180%;\n",
       "  font-weight:bold;\n",
       "  line-height: 1.2; \n",
       "  margin: 20px 50px 20px;\n",
       "  }\n",
       "\n",
       ".slide-header, p.slide-header\n",
       "{\n",
       "  color: #498AF3;\n",
       "  font-size: 200%;\n",
       "  font-weight:bold;\n",
       "  margin: 0px 20px 10px;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".rendered_html h1\n",
       "{\n",
       "  color: #498AF3;\n",
       "  line-height: 1.2; \n",
       "  margin: 0.15em 0em 0.5em;\n",
       "  page-break-before: always;\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       "\n",
       ".rendered_html h2\n",
       "{ \n",
       "  color: #386BBC;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html h3\n",
       "{ \n",
       "  font-size: 100%;\n",
       "  line-height: 1.2;\n",
       "  margin: 1.1em 0em 0.5em;\n",
       "  }\n",
       "\n",
       ".rendered_html li\n",
       "{\n",
       "  line-height: 1.8;\n",
       "  }\n",
       "\n",
       ".input_prompt, .CodeMirror-lines, .output_area\n",
       "{\n",
       "  font-family: Consolas;\n",
       "  font-size: 120%;\n",
       "  }\n",
       "\n",
       ".gap-above\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap01\n",
       "{\n",
       "  padding-top: 10px;\n",
       "  }\n",
       "\n",
       ".gap05\n",
       "{\n",
       "  padding-top: 50px;\n",
       "  }\n",
       "\n",
       ".gap1\n",
       "{\n",
       "  padding-top: 100px;\n",
       "  }\n",
       "\n",
       ".gap2\n",
       "{\n",
       "  padding-top: 200px;\n",
       "  }\n",
       "\n",
       ".gap3\n",
       "{\n",
       "  padding-top: 300px;\n",
       "  }\n",
       "\n",
       ".emph\n",
       "{\n",
       "  color: #386BBC;\n",
       "  }\n",
       "\n",
       ".warn\n",
       "{\n",
       "  color: red;\n",
       "  }\n",
       "\n",
       ".center\n",
       "{\n",
       "  text-align: center;\n",
       "  }\n",
       "\n",
       ".nb_link\n",
       "{\n",
       "    padding-bottom: 0.5em;\n",
       "}\n",
       "\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ../talktools.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">sklearn is not built for deep/complex networks such as required in covnets (as we'll see later on). We must go to specialized software (and potentially specialized hardware)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Deep Learning Frameworks\n",
    "\n",
    "Almost all frameworks written in low-level C++/C with Python (or other scripting bindings)\n",
    "\n",
    "### Low-level frameworks\n",
    "\n",
    "   - Tensorflow (Google) Nov 2015. See https://www.tensorflow.org/api_docs/python/tf\n",
    "   - Theano\n",
    "   - Caffe (Berkeley)\n",
    "   - Torch (Lua)\n",
    "   - pytorch (Python). https://pytorch.org/docs/stable/index.html\n",
    "   - CNTK (Microsoft)\n",
    "   - Chainer\n",
    "   - PaddlePaddle (Baidu) Aug 2016\n",
    "   \n",
    "### High level frameworks (Python)\n",
    "\n",
    "   - Keras (atop Tensorflow, Theano) - https://www.tensorflow.org/api_docs/python/tf/keras\n",
    "   - TFLearn \n",
    "   - nolearn\n",
    "   - SkFlow (part of tensorflow)\n",
    "   - [Lasagne](http://lasagne.readthedocs.io/en/latest/index.html) (atop Theano)\n",
    "   \n",
    "<img src=\"https://pbs.twimg.com/media/DX0lfBNU8AEs8KG.png:large\" width=\"75%\">\n",
    "Source: https://twitter.com/fchollet/status/971863128341323776\n",
    "\n",
    "<blockquote class=\"twitter-tweet\" data-lang=\"en\"><p lang=\"en\" dir=\"ltr\">TensorFlow is the platform of choice for deep learning in the research community. These are deep learning framework mentions on arXiv over the past 3 months <img src=\"https://pbs.twimg.com/media/DXy_uc0VAAAIhKG.jpg:small\">\n",
    "\n",
    "&mdash; Fran√ßois Chollet (@fchollet) <a href=\"https://twitter.com/fchollet/status/971863128341323776?ref_src=twsrc%5Etfw\">March 8, 2018</a></blockquote>\n",
    "<script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n",
    "\n",
    "\n",
    "see also: https://github.com/mbadry1/Top-Deep-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "\n",
    "\"Use Keras if you need a deep learning library that:\n",
    "\n",
    "Allows for easy and fast prototyping (through user friendliness, modularity, and extensibility).\n",
    "Supports both convolutional networks and recurrent networks, as well as combinations of the two.\n",
    "Runs seamlessly on CPU and GPU.\"\n",
    "\n",
    "-- keras.io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up the California housing data as in the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "\n",
    "cal_data = datasets.fetch_california_housing()\n",
    "X = cal_data['data']   # 8 features \n",
    "Y = cal_data['target'] # response (median house price)\n",
    "\n",
    "half = math.floor(len(Y)/2)\n",
    "train_X = X[:half]\n",
    "train_Y = Y[:half]\n",
    "test_X = X[half:]\n",
    "test_Y = Y[half:]\n",
    "\n",
    "\n",
    "scaler = StandardScaler()  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(train_X)  \n",
    "train_X = scaler.transform(train_X)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "test_X = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_features = train_X.shape[1]\n",
    "print(f'number of input features = {num_input_features}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime, os\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "# Print keras version\n",
    "print(tensorflow.keras.__version__)\n",
    "\n",
    "from tensorflow import keras\n",
    "print(f\"backend={keras.backend.backend()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_clf():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(32, input_shape=(num_input_features,), \n",
    "                      activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(32,  activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(10,  activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "    model.add(Dense(1, activation=\"linear\", kernel_initializer='random_uniform'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae',\"mse\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn_clf()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "from IPython.display import Image\n",
    "Image(\"model_plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "clf = KerasRegressor(build_fn=nn_clf, batch_size=32, epochs=50)\n",
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how well did we do?\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_Y, clf.predict(test_X)) ; print(\"MSE\",mse)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"NN Regression Residuals - MSE = %.3f\" % mse)\n",
    "plt.scatter(test_Y,clf.predict(test_X),alpha=0.4,s=3)\n",
    "plt.xlabel(\"Test Y\")\n",
    "plt.ylabel(\"Predicted Y\")\n",
    "plt.plot([0.2,5],[0.2,5],c=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A More Complete Example\n",
    "\n",
    "We want to train and make some decisions of when to stop based on `validation` data. Ultimately, we'd like to see how well our model would do on truly new data (`test`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percentage, valid_percentage, test_percentage = (0.90, 0.05, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rnd = np.random.RandomState(42)\n",
    "\n",
    "# make an array with the indices of all the rows in the dataset\n",
    "ind_arr = np.arange(X.shape[0])\n",
    "rnd.shuffle(ind_arr)\n",
    "\n",
    "train_ind, tmp = train_test_split(ind_arr, train_size=train_percentage, random_state=rnd)\n",
    "valid_ind, test_ind = train_test_split(tmp, \n",
    "                                                          train_size=valid_percentage/(valid_percentage + test_percentage), \n",
    "                                                          random_state=rnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure that we're getting all the indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(np.array(sorted(list(train_ind) + list(valid_ind) + list(test_ind)))  == sorted(ind_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ind.shape, test_ind.shape, valid_ind.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's scale the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()  \n",
    "\n",
    "train_X = X[train_ind]\n",
    "# Don't cheat - fit only on training data\n",
    "scaler.fit(train_X)  \n",
    "train_X = scaler.transform(train_X)  \n",
    "\n",
    "# apply same transformation to test, validation data\n",
    "test_X = scaler.transform(X[test_ind])\n",
    "valid_X = scaler.transform(X[valid_ind])\n",
    "\n",
    "train_y = Y[train_ind] ; test_y = Y[test_ind] ; valid_y = Y[valid_ind]\n",
    "\n",
    "assert train_y.shape[0] == train_X.shape[0]\n",
    "assert test_y.shape[0] == test_X.shape[0]\n",
    "assert valid_y.shape[0] == valid_X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(num_input_features,), \n",
    "                  activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "model.add(Dense(32,  activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "model.add(Dense(5,  activation=\"relu\", kernel_initializer='random_uniform'))\n",
    "model.add(Dense(1, activation=\"linear\", kernel_initializer='random_uniform'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Model.compile` method in `keras` has a number of input parameters:\n",
    "\n",
    "```python\n",
    "compile(optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "```\n",
    "Usually, you'll set the `optimizer`, `loss`, and `metrics`.\n",
    "\n",
    "https://keras.io/models/model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error',  metrics=['mae',\"mse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, CSVLogger, \\\n",
    "                                                ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "try:\n",
    "    os.mkdir('nn_results')\n",
    "except:\n",
    "    pass\n",
    "\n",
    "batch_size=64\n",
    "num_epochs = 200\n",
    "\n",
    "run_time_string = datetime.datetime.utcnow().isoformat(timespec='minutes')\n",
    "\n",
    "# define path to save model\n",
    "model_path = f'nn_results/datalab_nn_{run_time_string}.h5'\n",
    "print(f\"Training ... {model_path}\")\n",
    "\n",
    "# Tensorboard is a project which can ingest learning logs for interactive display...more on that later.\n",
    "tb = TensorBoard(log_dir='nn_results', histogram_freq=0,\n",
    "                 write_graph=True, \n",
    "                 write_grads=False, \n",
    "                 write_images=False, \n",
    "                 embeddings_freq=0, \n",
    "                 embeddings_layer_names=None, \n",
    "                 embeddings_metadata=None, embeddings_data=None)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_mse', factor=0.75,\n",
    "                              patience=3, min_lr=1e-6, verbose=1, cooldown=0)\n",
    "\n",
    "csv_logger = CSVLogger(f'nn_results/training_{run_time_string}.log')\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mse', min_delta=0.001, patience=10, \\\n",
    "                          verbose=1, mode='auto')\n",
    "\n",
    "model_check = ModelCheckpoint(model_path,\n",
    "        monitor='val_mse', \n",
    "        save_best_only=True, \n",
    "        mode='min',\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Model.fit` method:\n",
    "\n",
    "```python\n",
    "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x=train_X, y=train_y,\n",
    "               epochs=num_epochs,\n",
    "               validation_data=(valid_X, valid_y),\n",
    "               verbose=1, shuffle=True,\n",
    "               callbacks=[csv_logger, earlystop, model_check, tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls nn_results/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the history of the training results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lastest_log_file = !ls -t1 nn_results/training* | head -1\n",
    "hist_df = pd.read_csv(lastest_log_file[0])\n",
    "hist_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also available in the return value from `.fit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.title(\"Training History\")\n",
    "plt.plot(hist_df.index + 1,hist_df[\"val_mse\"] ,alpha=0.4, label=\"validation\")\n",
    "plt.plot(hist_df.index + 1,hist_df[\"mse\"] ,alpha=0.4, label=\"training\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss (MSE)\")\n",
    "plt.loglog()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the `tensorboard` notebook as well..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls nn_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload the best model\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "\n",
    "model = load_model(\"nn_results/datalab_nn_2020-04-13T21:24.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = model.predict(test_X)\n",
    "pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how well did we do?\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test_y, pred_y[:,0]); print(\"MSE\",mse)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.title(\"NN Regression Residuals - MSE = %.3f\" % mse)\n",
    "plt.scatter(test_y,pred_y[:,0] ,alpha=0.4,s=3)\n",
    "plt.xlabel(\"Test Y\")\n",
    "plt.ylabel(\"Predicted Y\")\n",
    "plt.plot([0.2,5],[0.2,5],c=\"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do compared to the validation and training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepCR]",
   "language": "python",
   "name": "conda-env-deepCR-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
